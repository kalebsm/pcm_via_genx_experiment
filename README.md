# insert DOI when available

<!-- Get rid of the metarepo instructions (the two sections below this) once you're done. -->

# metarepo
## [Check out the website for instructions](https://immm-sfa.github.io/metarepo)
`metarepo` is short for meta-repository, a GitHub repository that contains instructions to reproduce results in a published work. This repo is a template for creating your own metarepo.

## Purpose
A meta-repository creates a single point of access for someone to find all of the components that were used to create a published work for the purpose of reproducibility. This repository should contain references to all minted data and software as well as any ancillary code used to transform the source data, create figures for your publication, conduct the experiment, and / or execute the contributing software.

<!-- Get rid of the metarepo instructions (the two sections above this) once you're done. -->

# lastname-etal_year_journal

**your Paper Title here (once published, include a link to the text)**

First Last<sup>1\*</sup>, First Last<sup>1</sup>,  and First Last<sup>1, 2</sup>

<sup>1 </sup>Pacific Northwest National Laboratory, Richland, WA, USA.

<sup>2 </sup> Institute for Energy Analysis, Oak Ridge Associated Universities, Washington, DC, USA

\* corresponding author:  email@myorg.gov

## Abstract
_your abstract here_

## Journal reference
_your journal reference_

## Code reference
References for each minted software release for all code involved.  

These are generated by Zenodo automatically when conducting a release when Zenodo has been linked to your GitHub repository. The Zenodo references are built by setting the author order in order of contribution to the code using the author's GitHub username.  This citation can, and likely should, be edited without altering the DOI.

If you have modified a codebase that is outside of a formal release, and the modifications are not planned on being merged back into a version, fork the parent repository and add a `.<shortname>` to the version number of the parent and construct your own name.  For example, `v1.2.5.hydro`.

_your software reference here_

## Data reference

### Input data
Reference for each minted data source for your input data.  For example:

Human, I.M. (2021). My input dataset name [Data set]. DataHub. https://doi.org/some-doi-number

_your input data references here_

### Output data
Reference for each minted data source for your output data.  For example:

Human, I.M. (2021). My output dataset name [Data set]. DataHub. https://doi.org/some-doi-number

_your output data references here_


## Contributing modeling software
| Model | Version | Repository Link | DOI |
|-------|---------|-----------------|-----|
| ATB-calc | v0.0 | [link to code repository](https://github.com/NREL/ATB-calc) | [link to DOI dataset ](https://doi.org/10.11578/dc.20230914.2)|
| GenX | v0.4.4 | [link to code repository](https://github.com/kalebsm/GenX/tree/caee5563bc1118c24fe99a30e1ed72e052191478) \ [link to original code repository](https://github.com/GenXProject/GenX.jl) | [link to DOI dataset](https://zenodo.org/records/15865702) |
| SequentialNorta | v0.0 | link to code repository | link to DOI dataset |

## Program requirements
Running the scripts and computations will require the installation of the following:
1. A python version 3.10 or higher
2. A julia version 1.11 or higher
3. Gurobi license 9.4 or higher

Additionally, these experiments were originally run on an Intel i7-10700K CPU, 3.7 Ghz machine with 8 GB RAM. The total time for all 11 cases of the experiment to run on that machine was approximately 33 hours, or 3 hours per experiment (without parallelization).

## Reproduce my experiment
1. open a git bash terminal in the desired folder and enter: `git clone --recurse-submodules https://github.com/kalebsm/spcm_genx_experiment.git`
2. download the following ERCOT data from NREL ARPA-E PERFORM dataset and save in `spcm_genx_experiment\SPCM\src\scenario_generation\sequential_norta\data`

| #   | File Name                                | Data Type | Forecast Type         | Location Path                                               |
|-----|-------------------------------------------|-----------|------------------------|-------------------------------------------------------------|
| 1   | BA_lad_actuals_2018.h5                    | Load      | Actuals                | ERCOT/2018/Load/Actuals/BA_level/                           |
| 2   | BA_load_day-ahead_fcst_2018.h5            | Load      | Day-ahead Forecast     | ERCOT/2018/Load/Forecast/Day-ahead/BA_level/               |
| 3   | BA_solar_actuals_Existing_2018.h5         | Solar     | Actuals                | ERCOT/2018/Solar/Actuals/BA-level/                          |
| 4   | BA_solar_2day-ahead_fcst_Existing_2018.h5 | Solar     | 2-Day Ahead Forecast   | ERCOT/2018/Solar/2Day_ahead/BA_level/                      |
| 5   | BA_solar_day-ahead_fcst_Existing_2018.h5  | Solar     | Day-ahead Forecast     | ERCOT/2018/Solar/Day-ahead/BA_level/                       |
| 6   | BA_wind_actuals_Existing_2018.h5         | Wind*     | Actuals                | ERCOT/2018/Wind/Actuals/BA-level/                          |
| 7   | BA_wind_2day-ahead_fcst_Existing_2018.h5  | Wind      | 2-Day Ahead Forecast   | ERCOT/2018/Wind/2Day_ahead/BA_level/                       |
| 8   | BA_wind_day-ahead_fcst_Existing_2018.h5   | Wind      | Day-ahead Forecast     | ERCOT/2018/Wind/Day-ahead/BA_level/                        |




3. Install submodule repositories via the submodule links. One is a Fork of GenX, the other is a main branch of ATB-calc
4. Install the software components required to conduct the experiment from [contributing modeling software](#contributing-modeling-software)
5. Download and install the supporting [input data](#input-data) required to conduct the experiment
6. Run the following scripts in the `workflow` directory to re-create this experiment:

| Script Name | Description | How to Run |
| --- | --- | --- |
| `step_one.py` | Script to run the first part of my experiment | `python3 step_one.py -f /path/to/inputdata/file_one.csv` |
| `step_two.py` | Script to run the second part of my experiment | `python3 step_two.py -o /path/to/my/outputdir` |

4. Download and unzip the [output data](#output-data) from my experiment 
5. Run the following scripts in the `workflow` directory to compare my outputs to those from the publication

| Script Name | Description | How to Run |
| --- | --- | --- |
| `compare.py` | Script to compare my outputs to the original | `python3 compare.py --orig /path/to/original/data.csv --new /path/to/new/data.csv` |

## Reproduce my figures
Use the scripts found in the `figures` directory to reproduce the figures used in this publication.

| Figure Number(s) | Script Name | Description | How to Run |
| --- | --- | --- | --- |
| 1, 2 | `generate_plot.py` | Description of figure, ie. "Plots the difference between our two scenarios" | `python3 generate_plot.py -input /path/to/inputs -output /path/to/outuptdir` |
| 3 | `generate_figure.py` | Description of figure, ie. "Shows how the mean and peak differences are calculated" | `python3 generate_figure.py -input /path/to/inputs -output /path/to/outuptdir` |

